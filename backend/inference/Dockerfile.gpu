FROM ghcr.io/ggml-org/llama.cpp:server-cuda

# Create models directory for volume mount
USER root
RUN mkdir -p /models
RUN chown 1000:1000 /models

# Switch back to non-root user
USER 1000

EXPOSE 8080

# Just provide the arguments (ENTRYPOINT already has /app/llama-server)
# Use JSON array format to pass arguments to the existing entrypoint
CMD [
     "--model", "/models/gpt-oss-20b-Q5_K_S.gguf",
     "--host", "0.0.0.0",
     "--port", "8080",
     "--ctx-size", "8192",           # 8K ctx = half memory, faster KV ops
     "--threads", "8",               # match physical cores; use lscpu to verify
     "--batch-size", "256",          # smaller = quicker token turnaround
     "--ubatch-size", "128",         # lower microbatch for snappy response
     "--parallel", "2",              # allows one stream to generate while another waits (great for tool calls)
     "--cont-batching",              # keep cached prefix; reuse context across requests
     "--mlock",
     "--n-gpu-layers", "-1",
     "--jinja",
     "--reasoning-format", "none",
     "--context-shift",
     "--temp", "0.4",                # deterministic tool-calling
     "--top-p", "0.9",               # balanced sampling
     "--repeat-penalty", "1.1",      # reduces echoing when context shifts
     "--interactive-first",          # start streaming early
     "--parallel-threads", "2"       # (optional) enable concurrent token pipelines
   ]
   

# In order to use the GPU, we need to install the nvidia-container-toolkit on the host machine.

		# Add the package repositories
# distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
# curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
# curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

# # Install and restart Docker
# sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
# sudo systemctl restart docker

# You can test Docker GPU access with this
# docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
