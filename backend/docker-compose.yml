version: "3.8"

services:
  router:
    build: ./router
    ports:
      - "8000:8000"
      - "8443:8443"  # HTTPS port (uncomment if using SSL)
    environment:
      - ENVIRONMENT=development
      - LOG_LEVEL=DEBUG
      - HARMONY_ENABLED=true
      - HARMONY_REASONING_EFFORT=low
      - INFERENCE_URL=http://inference:8080
      # SSL Configuration (uncomment to enable)
      # - SSL_ENABLED=true
      # - SSL_CERT_PATH=/app/certificates/cert.pem
      # - SSL_KEY_PATH=/app/certificates/key.pem
      # - API_PORT=8443
    depends_on:
      - inference
    healthcheck:
      # Use HTTP for healthcheck (SSL_ENABLED=false) or HTTPS (SSL_ENABLED=true)
      test: ["CMD", "sh", "-c", "if [ \"$SSL_ENABLED\" = \"true\" ]; then curl -f -k https://localhost:8443/health; else curl -f http://localhost:8000/health; fi"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - geist-network

  inference:
    build: ./inference
    ports:
      - "8080:8080"
    platform: linux/arm64  # Force ARM64 for Apple Silicon
    environment:
      - MODEL_PATH=/models/gpt-oss-20b-Q4_K_S.gguf
      - HOST=0.0.0.0
      - PORT=8080
      - CONTEXT_SIZE=4096
      - THREADS=0 # Auto-detect CPU threads
      - GPU_LAYERS=${GPU_LAYERS:-0} # Set based on your GPU hardware: 0 for CPU-only, 32+ for NVIDIA GPUs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s # Model loading takes time
    deploy:
      resources:
        limits:
          memory: 16G # Adjust based on model size (GPT-OSS 20B needs more)
        reservations:
          memory: 4G
    # Apple Silicon M3 GPU acceleration happens automatically via Metal backend
    restart: unless-stopped
    networks:
      - geist-network

  embedder:
    build: ./embedder
    ports:
      - "8001:8001"
    environment:
      - ENVIRONMENT=development
      - LOG_LEVEL=DEBUG
      - API_HOST=0.0.0.0
      - API_PORT=8001
      - DEFAULT_MODEL=all-MiniLM-L6-v2
      - MODEL_CACHE_DIR=/app/models
    volumes:
      - embedder-models:/app/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 1G
    restart: unless-stopped
    networks:
      - geist-network

volumes:
  embedder-models:
    driver: local

networks:
  geist-network:
    driver: bridge